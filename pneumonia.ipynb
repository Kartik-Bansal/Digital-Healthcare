{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ETrfmYltJqVG"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import cv2\n",
    "from keras.models import Model\n",
    "import glob\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from scipy.signal.signaltools import wiener\n",
    "import h5py\n",
    "from google.colab import drive\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import keras.backend as K\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Input, Dense, Flatten, Dropout, BatchNormalization,Conv2D, SeparableConv2D, MaxPooling2D, LeakyReLU, Activation, GlobalMaxPooling2D\n",
    "from keras.optimizers import Adam\n",
    "import imgaug.augmenters as iaa\n",
    "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\n",
    "import tensorflow as tf\n",
    "from google_drive_downloader import GoogleDriveDownloader as gdd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ky6f7cnALB74",
    "outputId": "58e7c1df-b7f2-400f-a599-6080ccb764c3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading 1d_93d9oFNRBK9Vg6BRxs9wvRbKtNTylY into content/pneumonia_dataset.zip... Done.\n",
      "Unzipping...Done.\n"
     ]
    }
   ],
   "source": [
    "gdd.download_file_from_google_drive(file_id='1d_93d9oFNRBK9Vg6BRxs9wvRbKtNTylY',dest_path='content/pneumonia_dataset.zip',unzip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 229
    },
    "id": "PKMa_mF3R0Pr",
    "outputId": "e374f812-b7da-48a6-8e39-ede7d68c3d23"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-51-7bc3467d780d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg_to_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'img' is not defined"
     ]
    }
   ],
   "source": [
    "datagen = ImageDataGenerator(rescale=1./255, zoom_range=0.2, horizontal_flip = True, brightness_range=[0.7, 1.3]) \n",
    "img_dir = 'content/pneumonia_dataset/train/normal'  \n",
    "data_path = os.path.join(img_dir,'*g')\n",
    "files = glob.glob(data_path)\n",
    "data = []\n",
    "for f1 in files:\n",
    "    img = cv2.imread(f1)\n",
    "    data.append(img)\n",
    "\n",
    "x = img_to_array(img)\n",
    "x = x.reshape((1,) + x.shape)\n",
    "i = 0\n",
    "path, dirs, files = next(os.walk(\"content/pneumonia_dataset/train/normal\"))\n",
    "file_count = len(files) \n",
    "\n",
    "for batch in datagen.flow (x, batch_size=1, save_to_dir =r'train/aug-normal',save_prefix=\"a\",save_format='jpg'):\n",
    "    i+=1\n",
    "    if i==file_count*3:\n",
    "        break\n",
    "\n",
    "datagen = ImageDataGenerator(rescale=1./255, zoom_range=0.2, horizontal_flip = True, brightness_range=[0.7, 1.3]) \n",
    "img_dir = 'content/pneumonia_dataset/train/pneumonia'  \n",
    "data_path = os.path.join(img_dir,'*g')\n",
    "files = glob.glob(data_path)\n",
    "data = []\n",
    "for f1 in files:\n",
    "    img = cv2.imread(f1)\n",
    "    data.append(img)\n",
    "\n",
    "x = img_to_array(img)\n",
    "x = x.reshape((1,) + x.shape)\n",
    "i = 0\n",
    "path, dirs, files = next(os.walk(\"content/pneumonia_dataset/train/pneumonia\"))\n",
    "file_count = len(files) \n",
    "\n",
    "for batch in datagen.flow (x, batch_size=1, save_to_dir =r'train/aug-pneumonia',save_prefix=\"a\",save_format='jpg'):\n",
    "    i+=1\n",
    "    if i==file_count*3:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PZAQexzJKCcE"
   },
   "outputs": [],
   "source": [
    "train_X = []\n",
    "train_y = []\n",
    "dim=(299,299)\n",
    "\n",
    "img_folder_path='content/pneumonia_dataset/'\n",
    "mode = 'train'\n",
    "classes = os.listdir(os.path.join(img_folder_path, mode))\n",
    "for cl in classes:\n",
    "    files = os.listdir(os.path.join(img_folder_path, mode, cl))\n",
    "    for f in files:\n",
    "        image_path= os.path.join(img_folder_path,mode, cl, f)\n",
    "        img=cv2.imread(image_path,0)\n",
    "        img=img[20:980,20:980]\n",
    "        equ = cv2.equalizeHist(img)\n",
    "        img = cv2.resize(equ, dim)\n",
    "        img = np.dstack([img, img, img])\n",
    "        train_X.append(img)\n",
    "        if cl=='normal':\n",
    "             train_y.append(0)\n",
    "        else:\n",
    "             train_y.append(1)\n",
    "        \n",
    "train_X = np.asarray(train_X)\n",
    "train_y = np.asarray(train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8wOJQdaiYzas",
    "outputId": "91561ecc-86e1-4108-924e-02d7585164d1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2425, 299, 299, 3)\n",
      "(2425,)\n"
     ]
    }
   ],
   "source": [
    "print(train_X.shape)\n",
    "print(train_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Yz-3NRFGLlxF",
    "outputId": "7830245a-c4b0-4156-958c-8d5d45521785"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/xception/xception_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "83689472/83683744 [==============================] - 1s 0us/step\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "xception (Functional)        (None, 10, 10, 2048)      20861480  \n",
      "_________________________________________________________________\n",
      "global_max_pooling2d (Global (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 2)                 4098      \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 2)                 0         \n",
      "=================================================================\n",
      "Total params: 20,865,578\n",
      "Trainable params: 19,174,618\n",
      "Non-trainable params: 1,690,960\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.applications.xception import Xception\n",
    "\n",
    "input_shape = (299,299,3)\n",
    "\n",
    "model = Sequential()\n",
    "pretrained_model = Xception(input_shape = input_shape,  weights = 'imagenet',  include_top = False)\n",
    "for layer in pretrained_model.layers[:40]:\n",
    "      layer.trainable = False\n",
    "\n",
    "for layer in pretrained_model.layers:\n",
    "    if \"BatchNormalization\" in layer.__class__.__name__:\n",
    "        layer.trainable = True\n",
    " \n",
    "\n",
    "model.add(pretrained_model)\n",
    "\n",
    "model.layers.pop()\n",
    "model.layers.pop()\n",
    "model.layers.pop()\n",
    "\n",
    "model.add(GlobalMaxPooling2D())\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(0.75))\n",
    "model.add(Dense(2))\n",
    "model.add(Activation('sigmoid'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IrwlVZDDLpPz"
   },
   "outputs": [],
   "source": [
    "opt = Adam(lr=0.001, decay=1e-5)\n",
    "es = EarlyStopping(patience=5)\n",
    "chkpt = ModelCheckpoint(filepath='best_model_todate', save_best_only=True, save_weights_only=True)\n",
    "model.compile(loss='binary_crossentropy', metrics=['accuracy'],optimizer=opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "t9Xsjw6sVGUN",
    "outputId": "45331f6f-6f29-470b-ec07-c5ad1b128406"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2425, 2)\n"
     ]
    }
   ],
   "source": [
    "train_y=train_y.reshape(-1,1)\n",
    "train_y = OneHotEncoder().fit_transform(train_y).toarray()\n",
    "print(train_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lx97rSRDJuUU"
   },
   "outputs": [],
   "source": [
    "train_y2=train_y\n",
    "train_y = np.asarray(train_y).astype('float32').reshape((-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZOtfZeDPWJzV"
   },
   "outputs": [],
   "source": [
    "tf.config.run_functions_eagerly(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BR128g0PVOJ8",
    "outputId": "c04bc0d4-3135-4828-b67b-431ac017938a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "76/76 [==============================] - 3146s 41s/step - loss: 0.6829 - accuracy: 0.6227\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "Epoch 2/4\n",
      "76/76 [==============================] - 3215s 42s/step - loss: 0.5981 - accuracy: 0.6905\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "Epoch 3/4\n",
      "76/76 [==============================] - 3188s 42s/step - loss: 0.5617 - accuracy: 0.7237\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "Epoch 4/4\n",
      "76/76 [==============================] - 3180s 42s/step - loss: 0.4793 - accuracy: 0.7754\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f7bc800cdd0>"
      ]
     },
     "execution_count": 14,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_X, train_y2, verbose=1, epochs=4, callbacks = [es,chkpt])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SYQWR2PiRXBJ"
   },
   "outputs": [],
   "source": [
    "test_X = []\n",
    "dim=(299,299)\n",
    "img_folder_path='content/pneumonia_dataset/'\n",
    "\n",
    "mode='test'\n",
    "files = os.listdir(os.path.join(img_folder_path, mode))\n",
    "for f in files:\n",
    "        image_path= os.path.join(img_folder_path, mode, f)\n",
    "        img=cv2.imread(image_path,0)\n",
    "        img=img[20:980,20:980]\n",
    "        equ = cv2.equalizeHist(img)\n",
    "        img = cv2.resize(equ, dim)\n",
    "        img = np.dstack([img, img, img])\n",
    "        test_X.append(img)\n",
    "        \n",
    "test_X = np.asarray(test_X)\n",
    "preds = model.predict(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SeeJuYA5TEn5"
   },
   "outputs": [],
   "source": [
    "preds = model.predict(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1a_YUmfGTGW5"
   },
   "outputs": [],
   "source": [
    "sol=[]\n",
    "for i in range(len(preds)):\n",
    "    if preds[i][0] > preds[i][1]:\n",
    "        sol.append('normal')\n",
    "    else:\n",
    "        sol.append('pneumonia')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "w_-2C9RDUMzK",
    "outputId": "ac143110-76d3-4202-ef5e-32b7431f1b30"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['normal', 'pneumonia', 'pneumonia', 'pneumonia', 'normal', 'pneumonia', 'pneumonia', 'pneumonia', 'pneumonia', 'pneumonia', 'pneumonia', 'pneumonia', 'normal', 'pneumonia', 'normal', 'pneumonia', 'normal', 'pneumonia', 'normal', 'pneumonia', 'pneumonia', 'pneumonia', 'pneumonia', 'normal', 'pneumonia', 'pneumonia', 'pneumonia', 'pneumonia', 'pneumonia', 'normal', 'normal', 'pneumonia', 'pneumonia', 'pneumonia', 'normal', 'pneumonia', 'pneumonia', 'normal', 'pneumonia', 'normal', 'normal', 'pneumonia', 'pneumonia', 'normal', 'pneumonia', 'pneumonia', 'normal', 'pneumonia', 'pneumonia', 'pneumonia', 'normal', 'normal', 'pneumonia', 'pneumonia', 'pneumonia', 'normal', 'pneumonia', 'pneumonia', 'pneumonia', 'normal', 'normal', 'pneumonia', 'pneumonia', 'pneumonia', 'pneumonia', 'normal', 'pneumonia', 'normal', 'pneumonia', 'pneumonia', 'normal', 'normal', 'normal', 'pneumonia', 'normal', 'pneumonia', 'pneumonia', 'pneumonia', 'normal', 'normal', 'pneumonia', 'pneumonia', 'normal', 'normal', 'pneumonia', 'normal', 'pneumonia', 'normal', 'pneumonia', 'normal', 'pneumonia', 'pneumonia', 'pneumonia', 'normal', 'normal', 'pneumonia', 'normal', 'pneumonia', 'pneumonia', 'pneumonia', 'pneumonia', 'normal', 'normal', 'pneumonia', 'pneumonia', 'pneumonia', 'pneumonia', 'normal', 'pneumonia', 'pneumonia', 'normal', 'pneumonia', 'normal', 'normal', 'pneumonia', 'normal', 'pneumonia', 'pneumonia', 'pneumonia', 'normal', 'pneumonia', 'pneumonia', 'pneumonia', 'pneumonia', 'normal', 'pneumonia', 'normal', 'pneumonia', 'normal', 'pneumonia', 'pneumonia', 'pneumonia', 'pneumonia', 'normal', 'pneumonia', 'pneumonia', 'pneumonia', 'pneumonia', 'pneumonia', 'pneumonia', 'pneumonia', 'pneumonia', 'pneumonia', 'pneumonia', 'normal', 'normal', 'normal', 'pneumonia', 'normal', 'pneumonia', 'pneumonia', 'pneumonia', 'pneumonia', 'normal', 'normal', 'pneumonia', 'pneumonia', 'normal', 'normal', 'pneumonia', 'pneumonia', 'pneumonia', 'normal', 'normal', 'pneumonia', 'normal', 'normal', 'pneumonia', 'normal', 'normal', 'normal', 'pneumonia', 'pneumonia', 'pneumonia', 'normal', 'pneumonia', 'normal', 'pneumonia', 'normal', 'pneumonia', 'normal', 'normal', 'normal', 'normal', 'pneumonia', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'pneumonia', 'pneumonia', 'pneumonia', 'pneumonia', 'pneumonia', 'pneumonia', 'pneumonia', 'pneumonia', 'pneumonia', 'normal', 'normal', 'pneumonia', 'normal', 'pneumonia', 'pneumonia', 'normal', 'pneumonia', 'pneumonia', 'normal', 'pneumonia', 'pneumonia', 'pneumonia', 'pneumonia', 'normal', 'pneumonia', 'normal', 'pneumonia', 'pneumonia', 'pneumonia', 'pneumonia', 'pneumonia', 'pneumonia', 'normal', 'normal', 'normal', 'normal', 'normal', 'pneumonia', 'normal', 'normal', 'pneumonia', 'pneumonia', 'pneumonia', 'pneumonia', 'normal', 'pneumonia', 'normal', 'pneumonia', 'normal', 'pneumonia', 'normal', 'normal', 'pneumonia', 'pneumonia', 'pneumonia', 'pneumonia', 'pneumonia', 'normal', 'pneumonia', 'pneumonia', 'normal', 'pneumonia', 'pneumonia', 'pneumonia', 'pneumonia', 'pneumonia', 'pneumonia', 'normal', 'pneumonia', 'normal', 'normal', 'pneumonia', 'normal', 'normal', 'normal', 'pneumonia', 'pneumonia', 'pneumonia', 'normal', 'normal', 'pneumonia', 'pneumonia', 'pneumonia', 'pneumonia', 'normal', 'pneumonia', 'normal', 'pneumonia', 'normal', 'pneumonia', 'pneumonia', 'pneumonia', 'normal', 'pneumonia', 'normal', 'pneumonia', 'pneumonia', 'pneumonia', 'normal', 'normal', 'pneumonia', 'pneumonia', 'pneumonia', 'pneumonia', 'normal', 'normal', 'pneumonia', 'pneumonia', 'pneumonia', 'pneumonia', 'pneumonia', 'pneumonia', 'pneumonia', 'pneumonia', 'pneumonia', 'normal', 'pneumonia', 'pneumonia', 'pneumonia', 'normal', 'pneumonia', 'normal', 'normal', 'normal', 'normal', 'normal', 'pneumonia', 'pneumonia', 'normal', 'normal', 'normal', 'pneumonia', 'pneumonia', 'normal', 'pneumonia', 'normal', 'pneumonia', 'pneumonia', 'pneumonia', 'normal', 'normal', 'pneumonia', 'normal', 'pneumonia', 'normal', 'normal', 'pneumonia', 'pneumonia', 'pneumonia', 'normal', 'pneumonia', 'pneumonia', 'pneumonia', 'pneumonia', 'pneumonia', 'normal', 'normal', 'normal', 'pneumonia', 'pneumonia', 'normal', 'pneumonia', 'pneumonia', 'pneumonia', 'pneumonia', 'normal', 'pneumonia', 'pneumonia', 'normal', 'pneumonia', 'pneumonia', 'normal', 'normal', 'pneumonia', 'normal', 'pneumonia', 'pneumonia', 'pneumonia', 'pneumonia', 'pneumonia', 'pneumonia', 'normal', 'pneumonia', 'pneumonia', 'pneumonia', 'pneumonia', 'normal', 'pneumonia', 'normal', 'pneumonia', 'pneumonia', 'pneumonia', 'normal', 'normal', 'normal', 'pneumonia', 'pneumonia', 'pneumonia', 'normal', 'normal', 'pneumonia', 'normal', 'normal', 'pneumonia', 'pneumonia', 'normal', 'pneumonia', 'pneumonia', 'pneumonia', 'pneumonia', 'pneumonia', 'pneumonia', 'pneumonia', 'pneumonia', 'pneumonia', 'normal', 'pneumonia', 'pneumonia', 'normal', 'normal', 'pneumonia', 'pneumonia', 'pneumonia', 'pneumonia', 'normal', 'normal', 'pneumonia', 'normal', 'normal', 'pneumonia', 'pneumonia', 'pneumonia', 'pneumonia', 'pneumonia', 'pneumonia', 'normal', 'pneumonia', 'pneumonia', 'normal', 'normal', 'normal', 'pneumonia', 'pneumonia', 'normal', 'pneumonia', 'pneumonia', 'pneumonia', 'normal', 'pneumonia', 'normal', 'pneumonia', 'normal', 'normal', 'pneumonia', 'pneumonia', 'normal', 'normal', 'normal', 'pneumonia', 'pneumonia', 'pneumonia', 'pneumonia', 'normal', 'normal', 'pneumonia', 'normal', 'pneumonia', 'normal', 'normal', 'pneumonia', 'normal', 'pneumonia', 'pneumonia', 'pneumonia', 'normal', 'pneumonia', 'normal', 'normal', 'pneumonia', 'pneumonia', 'normal', 'pneumonia', 'normal', 'pneumonia', 'normal', 'pneumonia', 'normal', 'pneumonia', 'normal', 'pneumonia', 'pneumonia', 'normal', 'pneumonia', 'normal', 'pneumonia', 'pneumonia', 'normal', 'pneumonia', 'pneumonia', 'normal', 'normal', 'pneumonia', 'pneumonia', 'pneumonia', 'pneumonia', 'pneumonia', 'pneumonia', 'pneumonia', 'pneumonia', 'normal', 'normal', 'pneumonia', 'normal', 'pneumonia', 'normal', 'pneumonia', 'pneumonia', 'normal', 'pneumonia', 'pneumonia', 'normal', 'normal', 'normal', 'normal', 'pneumonia', 'pneumonia', 'normal', 'normal', 'pneumonia', 'pneumonia', 'pneumonia', 'pneumonia', 'normal', 'pneumonia', 'pneumonia', 'pneumonia', 'normal', 'normal', 'normal', 'pneumonia', 'pneumonia', 'pneumonia', 'pneumonia', 'pneumonia', 'pneumonia', 'normal', 'pneumonia', 'pneumonia', 'pneumonia', 'pneumonia', 'pneumonia', 'pneumonia', 'pneumonia', 'pneumonia', 'normal', 'pneumonia', 'pneumonia', 'normal', 'pneumonia', 'normal', 'normal', 'normal', 'pneumonia', 'pneumonia', 'pneumonia', 'normal', 'normal', 'normal', 'normal', 'pneumonia', 'pneumonia', 'pneumonia', 'normal', 'normal', 'normal', 'pneumonia', 'pneumonia', 'pneumonia', 'pneumonia', 'pneumonia', 'normal', 'normal', 'pneumonia', 'pneumonia', 'pneumonia', 'pneumonia', 'normal', 'pneumonia', 'pneumonia', 'pneumonia', 'normal', 'pneumonia', 'pneumonia', 'pneumonia', 'pneumonia', 'pneumonia', 'normal', 'pneumonia', 'pneumonia', 'normal', 'normal', 'normal', 'pneumonia', 'pneumonia', 'pneumonia', 'pneumonia', 'normal', 'pneumonia', 'pneumonia', 'pneumonia', 'normal', 'pneumonia', 'normal', 'pneumonia', 'pneumonia']\n"
     ]
    }
   ],
   "source": [
    "print(sol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cm6ttAVtUQun"
   },
   "outputs": [],
   "source": [
    "names_X = []\n",
    "dim=(299,299)\n",
    "img_folder_path='content/pneumonia_dataset/'\n",
    "\n",
    "mode='test'\n",
    "files = os.listdir(os.path.join(img_folder_path, mode))\n",
    "for f in files:\n",
    "      names_X.append(f)\n",
    "\n",
    "sol = pd.DataFrame(data = sol, columns = [\"label\"])\n",
    "sol['filename'] = names_X\n",
    "sol.to_csv(\"soln1.csv\")\n",
    "\n",
    "df=pd.read_csv('content/pneumonia_dataset/sample_submission.csv')\n",
    "df2=pd.read_csv('soln1.csv')\n",
    "df.drop('label',axis=1,inplace=True)\n",
    "f3 = df[[\"filename\"]].merge(df2[[\"filename\", \"label\"]], on = \"filename\", how = \"left\")\n",
    "f3.to_csv(\"Results.csv\", index = False)\n",
    "os.remove(\"soln1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2k2QR0fmUOMc"
   },
   "outputs": [],
   "source": [
    "ef vgg16_model(img_rows, img_cols, channel=1, num_classes=None):\n",
    "\n",
    "    model = VGG16(weights='imagenet', include_top=True)\n",
    "\n",
    "    model.layers.pop()\n",
    "\n",
    "    model.outputs = [model.layers[-1].output]\n",
    "\n",
    "    model.layers[-1].outbound_nodes = []\n",
    "\n",
    "          x=Dense(num_classes, activation='softmax')(model.output)\n",
    "\n",
    "    model=Model(model.input,x)\n",
    "\n",
    "\n",
    "          for layer in model.layers[:8]:\n",
    "\n",
    "       layer.trainable = False\n",
    "\n",
    "    sgd = SGD(lr=1e-3, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "    model.compile(optimizer=sgd, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "x963xPRwXpRd"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8U4_F5eSNCLF"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Untitled5.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
